---
title: "STAT-731 Recitation 4"
author: "K. Tyler Wilcox"
date: "September 28, 2016"
output:
  beamer_presentation:
    highlight: zenburn
    incremental: false
    theme: "metropolis"
---

```{r, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

Overview
========================================================

- Simulating Random Variables
- Special Discrete Distributions
- Law of Large Numbers
- Chebyshev's Theorem

Simulating Common Discrete Distributions
========================================================

- We've been doing this already
- Very useful way to deeply understand distributions
- Good way to simulate processes, models, and parameterizations

Example 1
========================================================

```{r, message = FALSE}
library(tidyverse); library(scales)
set.seed(55909666L)

r   = 5L
p   = 0.5
x   = 0L:(r + 10L)
px  = dnbinom(x, size = r, prob = p)
xpx = tibble(x = factor(x), px = px)
```

***

```{r, fig.height = 4, fig.cap = "$X \\sim \\text{NegBin}(n = 5, p = 0.5)$"}
xpx %>%
  ggplot(aes(x, px)) +
  geom_point() +
  theme_minimal()
```

Example 2
========================================================

```{r}
m   = 5L
p   = 1.0 / 20.0
x   = 0L:(m + 100L)
px  = dnbinom(x, size = m, prob = p)
xpx = tibble(x = factor(x), px = px)
```

***

```{r, echo = FALSE, fig.height = 6, fig.cap = "$X \\sim \\text{NegBin}(n = 5, \\theta = \\frac{1}{20})$"}
xpx %>%
  ggplot(aes(x, px)) +
  geom_point() +
  scale_x_discrete(breaks = seq(0L, 100L, by = 10L)) +
  theme_minimal()
```

Example 3
========================================================

```{r}
m      = 20L
lambda = 1.0
x      = 0L:m
px     = dpois(x, lambda)
xpx    = tibble(x = factor(x), px = px)
```

***

```{r, echo = FALSE, fig.height = 6, fig.cap = "$X \\sim \\text{Pois}(\\lambda = 1)$"}
xpx %>%
  ggplot(aes(x, px)) +
  geom_point() +
  theme_minimal()
```

Example 4
========================================================

```{r}
s   = 15L
f   = 10L
m   = 5L
x   = 0L:m
px  = dhyper(x, m = s, n = f, k = m)
xpx = tibble(x = factor(x), px = px)
```

***

```{r, echo = FALSE, fig.height = 6, fig.cap = "$X \\sim \\text{Hypergeo}(S = 15, F = 10, n = 5)$"}
xpx %>%
  ggplot(aes(x, px)) +
  geom_point() +
  theme_minimal()
```

Discrete Random Variables: Bernoulli Distribution
========================================================

- Consider a random variable $X$, $\mathcal{X} = \{ 0, 1 \}$ with $Pr[X = 1] = \theta$
- The probability mass function of $X$ is:
$$f_X(x) = \theta ^ {x} (1 - \theta) ^ {1 - x}, 0 < \theta  < 1$$
- We used this distribution when we considered a reasonable description of a coin flip

Simulating from the Bernoulli Distribution
========================================================

- Let $\theta = \frac{3}{4}$
- $\mathbb{E}[X] = \theta = \frac{3}{4}$
- Generate $m = 100$ empirical replications from Ber($\theta$)

```{r}
m     = 100L
n     = 1L
theta = 0.75
x     = rbinom(m, n, prob = theta)
avg   = mean(x)
```

- Empirical mean $\bar{X} = `r sprintf("%.4f", avg)`$

***

```{r, echo = FALSE, message = FALSE, fig.height = 4, fig.cap = "Empirical draws from $X \\sim \\text{Ber}(\\theta = 0.75)$"}
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 1.0), breaks = seq(0.0, 1.0, 0.1)) +
  theme_minimal()
```

***

- Let $\theta = \frac{1}{3}$
- $\mathbb{E}[X] = \theta = \frac{1}{3}$

```{r}
theta = 1.0 / 3.0
x     = rbinom(m, n, prob = theta)
avg   = mean(x)
```

***

- Empirical mean $\bar{X} = `r sprintf("%.4f", avg)`$

```{r, echo = FALSE, message = FALSE, fig.height = 6, fig.cap = "Empirical draws from $X \\sim \\text{Ber}(\\theta = \\frac{1}{3})$"}
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 1.0), breaks = seq(0.0, 1.0, 0.1)) +
  theme_minimal()
```

Discrete Random Variables: Binomial Distribution
========================================================

- Consider $n$ iid Bernoulli random variables $X_1, \ldots, X_n$
- Let $Y = \sum_{i = 1} ^ n X_i \sim \text{Binomial}(n, \theta)$
- The probability mass function of $Y$ is:
$$f_X(x) = {n \choose x} \theta ^ {x} (1 - \theta) ^ {n - x}, x \ge 0, \theta > 0$$
- $\mathbb{E}[X] = n \theta$
- Very common distribution with many applications

Simulating the Binomial as Sum of Bernoulli RVs
========================================================

- $\theta = 0.25$
- $\mathbb{E}[X] = n \theta = 1.25$

```{r}
m     = 1000L
n     = 5L
theta = 0.25
x = apply(matrix(rbinom(m * n, size = 1L,
                        prob = theta),
                 ncol = m), 2, sum)
xbar = mean(x)
```

- Empirical $\bar{X} = `r sprintf("%.4f", xbar)`$

***

```{r, echo = FALSE, fig.height = 4, fig.cap = "Empirical approximation of $X \\sim \\text{Bin}(n = 5, \\theta = 0.25)$ using draws from $X \\sim \\text{Ber}(\\theta = 0.25)$"}
x = tibble(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 1.0), breaks = seq(0.0, 1.0, 0.1)) +
  theme_minimal()
```

Simulating the Binomial Distribution Directly
========================================================

- Let $\theta = 0.25$
- Generate $m = 1000$ empirical replications from Bin($n = 5, \theta$)

```{r}
m     = 1000L
n     = 5L
theta = 0.25
x     = rbinom(m, n, prob = theta)
```

***

- Empirical $\bar{X} = `r sprintf("%.4f", mean(x))`$

```{r, echo = FALSE, fig.height = 5, fig.cap = "Empirical draws from $X \\sim \\text{Bin}(n = 5, \\theta = 0.25)$"}
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 1.0), breaks = seq(0.0, 1.0, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

Gaussian Approximation to Binomial Distribution
========================================================

- If $n$ is large, the Binomial distribution is relatively symmetric
- From the de Moivre-Laplace Theorem:
$$\text{Bin}\left( n, \theta \right) \stackrel{n}{\rightarrow} \text{N}\left(n \theta, n \theta (1 - \theta) \right)$$
- Basis of proportion hypothesis test using $\text{N}(0, 1)$

***

- $n = 5$
- Positively skewed

```{r, echo = FALSE, message = FALSE, fig.cap = "$X \\sim \\text{Bin}(n = 5, \\theta = \\frac{1}{3})$ PMF", fig.height = 4.5}
n     = 5L
theta = 1.0 / 3.0
x = rbinom(m, n, prob = theta)
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 0.5), breaks = seq(0.0, 0.5, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

***

- $n = 10$
- More symmetric, still skewed

```{r, echo = FALSE, message = FALSE, fig.cap = "$X \\sim \\text{Bin}(n = 10, \\theta = \\frac{1}{3})$ PMF", fig.height = 4.5}
n     = 10L
theta = 1.0 / 3.0
x = rbinom(m, n, prob = theta)
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 0.5), breaks = seq(0.0, 0.5, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

***

- $n = 30$
- Symmetric, approaching Gaussian distribution

```{r, echo = FALSE, message = FALSE, fig.cap = "$X \\sim \\text{Bin}(n = 30, \\theta = \\frac{1}{3})$ PMF", fig.height = 4.5}
n     = 30L
theta = 1.0 / 3.0
x = rbinom(m, n, prob = theta)
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 0.5), breaks = seq(0.0, 0.5, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

***

- $n = 100$
- Symmetric, approaching Gaussian distribution

```{r, echo = FALSE, message = FALSE, fig.cap = "$X \\sim \\text{Bin}(n = 100, \\theta = \\frac{1}{3})$ PMF", fig.height = 4.5}
n     = 100L
theta = 1.0 / 3.0
x = rbinom(m, n, prob = theta)
x = tibble(x = x) %>%
  mutate(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 0.5), breaks = seq(0.0, 0.5, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

Geometric Distribution
========================================================

- Let $X$ be the number of failures in a sequence of iid Bernoulli trials before a success occurs
- $\mathcal{X} = \{0, 1, ..., \infty\}$
- The geometric probability mass function:
$$f_X(x) = Pr[X = x] = \theta (1 - \theta) ^ x, x \ge 0, \theta > 0$$
- The geometric cumulative distribution function:
$$F_X(x) = 1 - (1 - \theta) ^ {k + 1}, x \ge 0, \theta > 0$$
- **Note:** in `R`, the geometric distribution `rgeom` has support for $X \in [0, \infty)$
- $\mathbb{E}[X] = \frac{1 - \theta}{\theta}$

***

- Consider $X \sim \text{Geom}(\theta)$ where $\theta = 0.4$
- $\mathbb{E}[X] = \frac{1 - \theta}{\theta} = 1.5$

```{r}
n     = 1000L
theta = 0.4
x     = rgeom(n, prob = theta)
expx  = (1.0 - theta) / theta
xbar  = mean(x)
```

- Empirical $\bar{X} = `r sprintf("%.4f", xbar)`$

***

```{r, echo = FALSE, fig.height = 4, fig.cap = "$X \\sim \\text{Geo}(\\theta = 0.4)$"}
x = tibble(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 1.0), breaks = seq(0.0, 1.0, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

***

- Consider $X \sim \text{Geom}(\theta)$ where $\theta = 0.8$
- $\mathbb{E}[X] = \frac{1 - \theta}{\theta} = 0.25$

```{r}
n     = 1000L
theta = 0.8
x     = rgeom(n, prob = theta)
expx  = (1.0 - theta) / theta
xbar  = mean(x)
```

- Empirical $\bar{X} = `r sprintf("%.4f", xbar)`$

***

```{r, echo = FALSE, fig.height = 4, fig.cap = "$X \\sim \\text{Geo}(\\theta = 0.8)$"}
x = tibble(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 1.0), breaks = seq(0.0, 1.0, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

Negative Binomial Distribution
========================================================

- Let $X$ be the number of failures in a sequence of iid Bernoulli trials before the $r$th success occurs
- $\mathcal{X} = \{0, 1, ..., \infty\}$
- The negative binomial probability mass function:
$$f_X(x) = Pr[X = x] = {{x + r - 1} \choose {x}} \theta ^ r (1 - \theta) ^ x, x \ge 0, \theta > 0$$
- $\mathbb{E}[X] =\frac{r (1 - \theta)}{\theta}$

Negative Binomial Distribution as Sum of IID Geometric Random Variables
========================================================

- Given $X_1, X_2, \ldots, X_n$ where $X_i \overset{iid}{\sim} F_X(x)$
- If $Y = \sum\limits_{i = 1}^{n} X_i$ then
$$M_Y(t) = \prod_{i = 1} ^ n M_{X_i}(t)$$

***

- Let $X_i \overset{iid}{\sim} \text{Geo}(\theta), i = 1, \ldots, r$
- $M_{X_i}(t) = \frac{\theta}{1 - (1 - \theta) e ^ t}$
\begin{align*}
  M_Y(t) &= \prod_{i = 1} ^ {r} M_{X_i}(t) \\
         &= \prod_{i = 1} ^ {r} \frac{\theta}{1 - (1 - \theta) e ^ t} \\
  M_Y(t) &= \left( \frac{\theta}{1 - (1 - \theta) e ^ t} \right) ^ r
\end{align*}
- $M_Y(t)$ can be recognized as the MGF of the Negative Binomial with $r$ failures

Simulating the Negative Binomial as Sum of Geometric RVs
========================================================

- $\theta = 0.5$
- $\mathbb{E}[X] = \frac{r ( 1 - \theta)}{\theta} = 5$

```{r}
m     = 1000L
r     = 5L
theta = 0.5
x = apply(matrix(rgeom(m * r,
                       prob = theta),
                 ncol = m), 2, sum)
xbar = mean(x)
```

- Empirical $\bar{X} = `r sprintf("%.4f", xbar)`$

***

```{r, echo = FALSE, fig.height = 4, fig.cap = "Empirical approximation of $X \\sim \\text{NegBin}(r = 5, \\theta = 0.5)$ using draws from $X \\sim \\text{Geo}(\\theta = 0.5)$"}
x = tibble(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 0.5), breaks = seq(0.0, 0.5, 0.1)) +
  theme_minimal()
```

***

- Using the negative binomial directly:

```{r}
n     = 1000L
r     = 5L
theta = 0.5
x     = rnbinom(n, size = r, prob = theta)
xbar  = mean(x)
```

- Empirical $\bar{X} = `r sprintf("%.4f", xbar)`$

***

```{r, echo = FALSE, fig.height = 4, fig.cap = "$X \\sim \\text{NegBin}(r = 5, \\theta = 0.5)$"}
x = tibble(x = factor(x))
x %>%
  ggplot() +
  geom_bar(aes(x, ..count.. / sum(..count..))) +
  scale_y_continuous(name = "Relative Frequency", labels = percent,
                     limits = c(0.0, 0.5), breaks = seq(0.0, 0.5, 0.1)) +
  ggtitle("Empirical Probability of X") +
  theme_minimal()
```

Arbitrary Discrete Distribution
========================================================

- Suppose $X \in {x_1, x_2, x_3, \ldots, x_k}$
- $P_X(x) \in {p(x_1), p(x_2), p(x_3), \ldots, p(x_k)}$
- Let $\mathcal{X} = {-2, -1, 0, 3, 4}$
- Let $P_X(x) = {0.125, 0.25, 0.25, 0.25, 0.125}$
- $\mathbb{E}[X] = 0.75$
- $\mathbb{E}[X ^ 2] = 5$
- $\mathbb{V}[X] = \mathbb{E}[X ^ 2] - \mathbb{E}[X] ^ 2 = 4.4375$

***

```{r}
xpx = tibble(
  x  = c(-2, -1, 0, 3, 4),
  px = c(0.125, 0.25, 0.25, 0.25, 0.125))
```

```{r, echo = FALSE, fig.cap = "An arbitrary PMF for $X \\sim F_X(x)$", fig.height = 4.5}
xpx %>%
  ggplot() +
  geom_point(aes(x, px)) +
  scale_x_continuous(breaks = -2L:4L, labels = -2L:4L) +
  scale_y_continuous(name = "Pr[X = x]", limits = c(0.0, 0.3),
                     breaks = seq(0.0, 0.3, 0.05)) +
  theme_minimal()
```

***

- Simulate $n$ random variates from $F_X(x)$

```{r}
n = 100000L
d = sample(xpx$x, size = n, replace = TRUE, prob = xpx$px)

# Empirical (sample) average
xbar = mean(d)
varx = var(d)
```

- $\bar{X} = `r sprintf("%.4f", xbar)`$
- $s ^ 2 = `r sprintf("%.4f", varx)`$

Wrapping Up
========================================================

- Probability Mass Functions
- Probability Density Functions
- Cumulative Distribution Functions
- Approximation with Monte Carlo
- Questions?
